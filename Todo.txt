========================================
🚀 Agent2 구현 계획서 (3개 Tools + 1개 Agent 구조)
========================================
작성일: 2025-08-29 (수정)
목표: AI.png 플로우차트 Agent2 구현 (오늘 오전 중 완성)

========================================
🔍 현재 상황 및 목표
========================================

🚨 **핵심 문제점**
- Agent2가 완전히 누락됨
- predata 기반 생성된 템플릿의 검증 로직 없음
- 광고성 메시지 "광고" 표기 누락 감지 불가

🎯 **오늘 구현 목표 (Agent2)**
- 3개 Tools: BlackList, WhiteList, InfoCommLaw
- 1개 Agent: GuidelineJudgeAgent (8개 MD파일 통합 LLM 판단)
- RunnableParallel 병렬 처리
- main.py 통합 및 테스트

========================================
📋 Agent2 구현 단계 (오전 중 완성 목표)
========================================

🔧 Step 1: 3개 Tools 구현 (1시간)
--------------------------------
[ ] 🚨 tools/ 폴더 생성
[ ] 🚨 BlackListTool 구현 (tools/blacklist_tool.py)
    - predata/cleaned_black_list.md 기반 금지어/패턴 검증
    - 광고성 내용이지만 "광고" 표기 누락 감지
    - 위험도 점수 계산 및 대체어 제안
    
[ ] 🚨 WhiteListTool 구현 (tools/whitelist_tool.py)
    - predata/cleaned_white_list.md 기반 승인 패턴 매칭
    - 필수 요소 포함 여부 검증 (수신거부, 발신자 정보)
    - 컴플라이언스 점수 계산
    
[ ] 🚨 InfoCommLawTool 구현 (tools/info_comm_law_tool.py)
    - predata/pdf_extraction_results.txt 기반 법령 검증
    - 정보통신망법 조항별 체크리스트
    - 법적 리스크 평가

🔧 Step 2: GuidelineJudgeAgent 구현 (1시간)
------------------------------------------
[ ] 🚨 agents/ 폴더 생성
[ ] 🚨 GuidelineJudgeAgent 구현 (agents/guideline_judge_agent.py)
    - 8개 MD 파일 통합 로드 (predata/*.md)
    - LLM as a Judge: Gemini 2.0 Flash 활용
    - Tools 결과를 참고한 종합적 가이드라인 준수 판단
    - JSON 형태 구조화된 응답 (점수, 위반사항, 개선제안)

🔧 Step 3: Agent2 메인 클래스 구현 (30분)
----------------------------------------
[ ] 🚨 Agent2 클래스 생성 (agents/agent2.py)
    - RunnableParallel로 3개 Tools 병렬 실행
    - GuidelineJudgeAgent와 Tools 결과 통합
    - ALL PASS 검증 로직 구현
    - 최종 승인/반려 결정 및 피드백 생성

🔧 Step 4: main.py 통합 및 테스트 (30분-1시간)
--------------------------------------------
[ ] 🚨 TemplateSystem에 Agent2 추가
    - 템플릿 생성 후 Agent2 검증 단계 추가
    - Agent2 실패 시 재생성 또는 수정 로직
    - 검증 결과 사용자 피드백
    
[ ] 🚨 전체 플로우 테스트
    - 각 Tool 개별 테스트
    - Agent2 통합 테스트  
    - 실제 템플릿 생성 → Agent2 검증 전체 플로우

========================================
📋 구현 세부 사항
========================================

🔧 각 Tool 공통 구조
------------------
```python
from langchain.tools import BaseTool

class XxxTool(BaseTool):
    name = "tool_name"
    description = "도구 설명"
    
    def _run(self, template: str) -> Dict:
        # 1. predata 파일 로드
        # 2. 템플릿 검증 로직
        # 3. 점수 계산 (0-100)
        # 4. 결과 반환 {"pass": True/False, "score": 점수, "issues": [], "suggestions": []}
```

🔧 필수 라이브러리 설치
---------------------
[ ] 🚨 LangChain 설치: pip install langchain
[ ] 🚨 추가 의존성: pip install langchain-google-genai

========================================  
📋 완료 체크리스트
========================================

✅ **완료 기준**
[ ] 3개 Tools 개별 테스트 성공
[ ] GuidelineJudgeAgent LLM 응답 정상
[ ] Agent2 병렬 처리 정상 동작
[ ] main.py 전체 플로우 테스트 성공
[ ] 광고성 메시지 "광고" 표기 누락 감지 가능

📋 **예상 소요 시간: 3-4시간**
- Step 1 (3개 Tools): 1시간
- Step 2 (GuidelineAgent): 1시간  
- Step 3 (Agent2): 30분
- Step 4 (통합&테스트): 30분-1시간

========================================
📋 주의사항
========================================

⚠️ **구현 시 주의점**
- BlackListTool: 광고성 키워드 있으면서 "[광고]" 표기 없을 때 FAIL
- WhiteListTool: 필수 요소 누락 시 구체적 피드백 제공
- GuidelineJudgeAgent: 8개 MD 파일 로드 시 토큰 제한 고려
- Agent2: ALL PASS 조건 - 모든 검증이 통과해야 최종 승인

💡 **성공 팁**
- 각 단계별 개별 테스트 먼저 수행
- 에러 발생 시 fallback 로직 필수 구현
- 사용자 피드백은 구체적이고 실행 가능하게


========================================
📋 PHASE 5.5: AI 학습 시스템 구축 (사용자 언급 반영)
========================================

🤖 5.5.1 반려 사유 기반 학습 시스템
---------------------------------
[ ] 🚨 ReasonClassifier 구현 (ai_learning/reason_classifier.py)
    - **반려 사유 분류**: 법적 위험, 내용 부적절, 형식 오류 등
    - **패턴 학습**: 반복되는 반려 사유 자동 감지
    - **개선 제안 생성**: 구체적인 수정 방법 제시

[ ] 🚨 TemplatePattern 학습 시스템
    - **승인 템플릿 패턴 분석**: 성공 사례 특징 추출
    - **반려 템플릿 패턴 분석**: 실패 원인 패턴 학습  
    - **템플릿 품질 예측**: 승인 가능성 사전 평가

[ ] 🚨 FeedbackLoop 구현 (ai_learning/feedback_loop.py)
    - **실시간 학습**: 심사 결과 → 즉시 모델 업데이트
    - **A/B 테스트**: 다른 생성 방식 성능 비교
    - **성능 추적**: 시간별 정확도 개선 모니터링

🤖 5.5.2 승인/반려 템플릿 데이터셋 구축
-----------------------------------
[ ] 🚨 DataCollector 구현 (ai_learning/data_collector.py)
    - **승인 템플릿 수집**: 카카오 심사 통과 사례
    - **반려 템플릿 수집**: 반려 사유별 분류 저장
    - **메타데이터 태깅**: 카테고리, 업종, 위험도 등

[ ] 🚨 TrainingDataPreparer
    - **데이터 전처리**: 개인정보 마스킹, 정규화
    - **균형잡힌 샘플링**: 승인/반려 비율 조정
    - **품질 검증**: 라벨링 정확도 확인

🤖 5.5.3 지능형 템플릿 생성 AI
----------------------------
[ ] 🚨 SmartTemplateGenerator (core/smart_template_generator.py)
    - **기존 TemplateGenerator 고도화**
    - **학습된 패턴 활용**: 성공 확률 높은 구조 선택
    - **실시간 최적화**: 생성 중 품질 점수 계산
    - **다양성 보장**: 3가지 스타일 자동 생성

========================================
📋 PHASE 6: 테스트 및 배포 (현재 시스템 대비)
========================================

🧪 6.1 테스트 시스템 - **현재 없음**
----------------------------------
[ ] 🚨 단위 테스트 (각 Tool별) - **pytest 도입 필요**
[ ] 🚨 통합 테스트 (Agent 간 협업) - **Agent 개발 후 필요**
[ ] 🚨 성능 테스트 (대용량 데이터) - **현재 소규모 데이터만**
[ ] 🚨 엣지 케이스 테스트 - **현재 없음**

🧪 6.2 품질 보증
---------------
[ ] 코드 리뷰 체크리스트
[ ] 보안 취약점 점검
[ ] 데이터 프라이버시 검증
[ ] 성능 기준 충족 확인

🧪 6.3 배포 및 운영
------------------
[ ] Docker 컨테이너화
[ ] CI/CD 파이프라인 구축
[ ] 모니터링 및 알림 시스템
[ ] 백업 및 복구 계획

========================================
🎯 우선순위 및 타임라인
========================================

🚨 HIGH PRIORITY (1-2주)
- Agent2 + 4개 Tools 구현
- RunnableParallel 병렬 처리
- 기본적인 플로우 제어

⚡ MEDIUM PRIORITY (3-4주)  
- SOT 시스템 구축
- 성능 최적화
- 에러 핸들링 강화

💡 LOW PRIORITY (5주 이후)
- 고급 기능들
- API 구현
- 대시보드 개발

========================================
🔧 기술 스택 권장사항
========================================

핵심 프레임워크:
- LangChain (Agent, Tools, Runnables)
- FAISS (벡터 검색)
- Google Generative AI (Gemini)

성능 최적화:
- asyncio (비동기 처리)
- Redis (캐싱)
- PostgreSQL (메타데이터 저장)

모니터링:
- Prometheus + Grafana
- LangSmith (LLM 추적)
- 커스텀 로깅 시스템

========================================
📝 개발 가이드라인
========================================

1. 코드 구조:
   - 각 Agent는 독립적인 모듈
   - Tool은 재사용 가능한 컴포넌트
   - 설정은 환경변수로 관리

2. 에러 처리:
   - 모든 외부 API 호출에 재시도 로직
   - 사용자 친화적 에러 메시지
   - 로그는 구조화된 형태로 기록

3. 성능 고려사항:
   - 임베딩은 배치로 처리
   - 결과는 적극적으로 캐싱
   - 메모리 사용량 모니터링

4. 보안:
   - API 키는 환경변수로만 관리
   - 입력 데이터 검증 필수
   - 민감한 정보 로깅 금지

========================================
📋 PHASE 7: RAGAS 평가 시스템 (핵심 추가)
========================================

🌟 7.1 RAGAS 평가 프레임워크 구축
--------------------------------
[ ] RAGAS 라이브러리 통합 (requirements.txt 업데이트)
[ ] RAGASEvaluator 클래스 구현 (evaluation/ragas_evaluator.py)
    - Faithfulness 평가 (생성된 답변의 신뢰성)
    - Answer Relevancy 평가 (답변의 관련성)
    - Context Precision 평가 (컨텍스트 정확도)
    - Context Recall 평가 (컨텍스트 재현율)
[ ] 3회 반복 평가 시스템 구현
    - 평가 결과 일관성 검증
    - 평균/최소/최대 점수 계산
    - 신뢰도 구간 계산

🌟 7.2 평가 기준 시스템
----------------------
[ ] EvaluationCriteria 클래스 구현 (evaluation/criteria.py)
[ ] 동적 기준 설정 시스템
    - 카테고리별 통과 기준 (예약확인: 85점, 이벤트: 80점)
    - 긴급도별 기준 조정
    - A/B 테스트를 위한 기준 변형
[ ] 기준 관리 인터페이스
    - 기준 변경 히스토리
    - 기준 효과 분석
    - 자동 기준 최적화

🌟 7.3 평가 결과 관리
--------------------
[ ] EvaluationResult 데이터 모델
[ ] 평가 상세 리포트 생성
    - 실패 원인 분석
    - 개선 제안 생성
    - 유사 성공 사례 추천
[ ] 평가 결과 시각화
    - 점수 분포 차트
    - 시간별 성능 트렌드
    - 카테고리별 성능 비교

========================================
📋 PHASE 7.5: 마이크로서비스 아키텍처 구축 (12.png 반영)
========================================

🏗️ 7.5.1 Spring Boot API 서버 구축
----------------------------------
[ ] Spring Boot 프로젝트 초기화 (backend/spring-api/)
[ ] RESTful API 엔드포인트 설계 - 백엔드 API 명세서 기반
    - POST /api/auth/signup (회원가입)
    - GET /api/auth/verify?token={verifyToken} (이메일 인증)
    - POST /api/auth/login (로그인)
    - POST /api/auth/logout (로그아웃)
    - POST /api/auth/refresh (토큰 재발급)
    - PUT /api/auth/password (비밀번호 변경-로그인)
    - POST /api/auth/password/reset-request (비번 재설정 요청-비로그인)
    - POST /api/auth/password/reset (비번 재설정)
    - PUT /api/admin/users/{id}/roles (권한 변경-관리자)
    - GET /api/users/me (내 정보 조회)
    - POST /api/templates (템플릿 생성)
    - GET /api/templates (템플릿 목록 조회)
    - GET /api/templates/{id} (템플릿 상세 조회)
    - GET /api/admin/templates/{id}/history (템플릿 이력 조회)
[ ] FastAPI 서비스와 HTTP 통신 구현
    - RestTemplate 또는 WebClient 설정
    - 타임아웃 및 재시도 로직
    - 에러 핸들링 및 fallback
[ ] 요청/응답 DTO 클래스 정의
[ ] API 문서화 (Swagger/OpenAPI)
[ ] JWT 기반 인증/인가 시스템 구현
[ ] 관리자 권한 관리 시스템

🏗️ 7.5.2 FastAPI AI 엔진 서버 분리
----------------------------------
[ ] 현재 Python 코드를 FastAPI 서비스로 변환
[ ] FastAPI 프로젝트 구조 설계 (ai-engine/)
    - /generate: 템플릿 생성 엔드포인트
    - /evaluate: RAGAS 평가 엔드포인트  
    - /validate: Agent1/Agent2 검증 엔드포인트
[ ] 비동기 처리 구현 (async/await)
    - Agent 처리 비동기화
    - RAGAS 평가 비동기화
    - 데이터베이스 연동 비동기화
[ ] Pydantic 모델 정의 (요청/응답 스키마)
[ ] FastAPI 미들웨어 설정
    - CORS 설정
    - 로깅 미들웨어
    - 인증/인가 미들웨어

🏗️ 7.5.3 Mock 카카오 API 시뮬레이터
----------------------------------
[ ] Mock 카카오 API 서버 구현 (mock-kakao-api/)
[ ] 템플릿 심사 시뮬레이션 로직
    - 승인/반려 규칙 엔진
    - 심사 소요시간 시뮬레이션
    - 반려 사유 생성 로직
[ ] Webhook 콜백 구현
    - 비동기 심사 결과 전송
    - 재시도 메커니즘
    - 실패 처리 로직
[ ] 관리자 인터페이스
    - 심사 기준 조정
    - 심사 히스토리 조회
    - 성능 모니터링

🏗️ 7.5.4 서비스 간 통신 최적화
-----------------------------
[ ] 로드 밸런싱 구현
[ ] 서킷 브레이커 패턴 적용
[ ] 분산 캐싱 (Redis) 연동
[ ] 메시지 큐 시스템 (RabbitMQ/Kafka) 검토
[ ] 서비스 디스커버리 구현
[ ] 헬스체크 엔드포인트 구현

========================================
📋 PHASE 8: MySQL 데이터베이스 연동 (수정)
========================================

🗄️ 8.1 데이터베이스 설계
------------------------
[ ] MySQL 스키마 설계 (database/schema.sql)
    - templates 테이블 (승인된 템플릿)
    - evaluations 테이블 (평가 결과)
    - template_versions 테이블 (버전 관리)
    - evaluation_history 테이블 (평가 히스토리)
    - user_feedback 테이블 (사용자 피드백)
[ ] 인덱스 최적화
    - 템플릿 검색 성능 향상
    - 평가 결과 조회 최적화
    - 시간 기반 쿼리 최적화

🗄️ 8.2 데이터베이스 연동 시스템
------------------------------
[ ] DatabaseManager 클래스 구현 (database/manager.py)
[ ] SQLAlchemy ORM 모델 정의 (database/models.py)
    - Template 모델
    - Evaluation 모델  
    - TemplateVersion 모델
    - EvaluationHistory 모델
[ ] 데이터베이스 연결 풀링
[ ] 트랜잭션 관리 시스템
[ ] 자동 백업 시스템

🗄️ 8.3 템플릿 저장 워크플로우
----------------------------
[ ] 평가 통과 시 자동 저장 로직
[ ] 템플릿 메타데이터 관리
    - 생성일시, 수정일시
    - 버전 정보
    - 성능 지표
    - 사용 통계
[ ] 중복 템플릿 검증
[ ] 저장 실패 시 재시도 메커니즘

========================================
📋 PHASE 9: 실데이터 검증 시스템
========================================

🧪 9.1 테스트 데이터셋 구축
--------------------------
[ ] 심사 통과 템플릿 데이터셋 준비
    - 다양한 카테고리별 샘플 (예약, 결제, 이벤트 등)
    - 품질 등급별 분류 (우수, 양호, 보통)
    - 메타데이터 태깅 (난이도, 복잡도, 특수케이스)
[ ] 심사 반려 템플릿 데이터셋 준비
    - 반려 사유별 분류
    - 법적 위험도별 분류
    - 수정 가능성 평가
[ ] 테스트 케이스 자동 생성 시스템
    - 엣지 케이스 생성
    - 경계값 테스트 케이스
    - 부정 테스트 케이스

🧪 9.2 자동화 테스트 시스템
--------------------------
[ ] TestRunner 클래스 구현 (testing/runner.py)
[ ] 배치 테스트 실행 시스템
    - 대량 데이터 처리
    - 병렬 테스트 실행
    - 진행률 모니터링
[ ] 성능 벤치마킹
    - 응답 시간 측정
    - 메모리 사용량 추적
    - CPU 사용률 모니터링
[ ] 정확도 검증 시스템
    - Confusion Matrix 생성
    - Precision/Recall 계산
    - F1-Score 측정

🧪 9.3 검증 결과 분석
--------------------
[ ] TestAnalyzer 클래스 구현 (testing/analyzer.py)
[ ] 거짓 양성/음성 분석
    - 오탐 원인 분석
    - 누락 원인 분석
    - 개선 우선순위 도출
[ ] 성능 개선 제안 시스템
    - 병목 구간 식별
    - 최적화 방안 제시
    - 효과 예측 모델
[ ] 리포트 자동 생성
    - 일일 검증 리포트
    - 주간 성능 분석
    - 월간 개선 제안

========================================
📋 PHASE 10: 통합 워크플로우 (최종 단계)
========================================

🔄 10.1 완전한 파이프라인 구축
-----------------------------
[ ] MasterPipeline 클래스 구현 (pipeline/master.py)
    1. 사용자 입력 → Agent1 (가이드라인 검증)
    2. Agent1 통과 → 템플릿 생성 
    3. 템플릿 → Agent2 (4개 Tools 병렬 검증)
    4. Agent2 통과 → RAGAS 3회 평가
    5. 평가 통과 → MySQL 저장
    6. 저장 완료 → 사용자에게 결과 반환
[ ] 각 단계별 에러 처리 및 롤백
[ ] 단계별 로깅 및 추적
[ ] 성능 모니터링 통합

🔄 10.2 피드백 루프 시스템
-------------------------
[ ] 실패 시 개선 제안 생성
    - Agent1 실패 → 입력 가이드 제공
    - Agent2 실패 → 컴플라이언스 이슈 안내
    - RAGAS 실패 → 품질 개선 제안
[ ] 학습 기반 개선 시스템
    - 실패 패턴 학습
    - 성공 패턴 강화
    - 자동 기준 조정
[ ] 사용자 피드백 수집
    - 만족도 조사
    - 개선 요청 수집
    - 사용 패턴 분석

🔄 10.3 운영 모니터링
--------------------
[ ] 실시간 대시보드 구현
    - 시스템 상태 모니터링
    - 성능 지표 추적
    - 에러율 모니터링
[ ] 알림 시스템 구축
    - 장애 감지 알림
    - 성능 저하 경고
    - 용량 부족 알림
[ ] 자동 스케일링
    - 부하에 따른 자동 확장
    - 리소스 최적화
    - 비용 효율성 관리

========================================
🚨 핵심 수정사항 및 주의점
========================================

🔴 **아키텍처 대폭 수정 (12.png 반영)**
기존 계획: Python 단일 시스템 (main.py)
12.png 기준: 마이크로서비스 아키텍처
→ **Spring Boot (API) + FastAPI (AI엔진) + Mock 카카오 API 구조**

🔴 **워크플로우 순서 수정**
현재 계획: 템플릿 생성 → Agent2 → RAGAS
AI.png 기준: Agent1 → 템플릿 생성 → Agent2 → RAGAS
→ **Agent1 가이드라인 검증을 먼저 수행해야 함**

🔴 **Agent1 구현 우선순위 상향**
- 현재 MEDIUM → HIGH로 변경
- Agent2와 동시 개발 필요
- 가이드라인 검증 없이는 품질 보장 불가

🔴 **RAGAS 평가 기준 사전 정의 필요**
- "추후 적용"이 아닌 개발 초기 단계에서 정의
- 테스트 데이터 기반 기준 수립
- 지속적 기준 개선 체계 필요

🔴 **데이터베이스 트랜잭션 고려**
- 평가 실패 시 부분 저장 방지
- 원자적 저장 처리 필수
- 롤백 메커니즘 구현

🔴 **성능 고려사항**
- RAGAS 3회 평가로 인한 지연 시간
- MySQL 저장 성능 최적화
- 대량 실데이터 처리 최적화

========================================
🎯 RAG → LangChain → LangGraph 순차 개발 계획 (12.png + AI.png 반영)
========================================

🚨 **PHASE 1: RAG 시스템 강화 (1-2주) - 현재 코드 기반**
================================================================

🔧 1.1 현재 시스템 안정화 및 최적화
---------------------------------
[ ] 🚨 LLM-as-a-judge 구현 (core/llm_judge.py) - **신규**
    - 비속어/부적절한 내용 실시간 판단
    - Gemini 2.0 Flash 활용한 콘텐츠 심사
    - 위험도 레벨 분류 (low/medium/high)
    - JSON 형태 구조화된 응답

[ ] 🚨 SemScore 기반 Smart Modifier 구현 (core/smart_modifier.py) - **신규**
    - SentenceTransformer 활용 단어 유사성 분석
    - 블랙리스트 단어 → 화이트리스트 대체어 매핑
    - 가이드라인 준수 수정본 자동 생성
    - 컴플라이언스 점수 계산

[ ] 🚨 실시간 URL 스크래핑 시스템 (utils/url_scraper.py) - **신규**
    - 카카오 공식 가이드라인 페이지 모니터링
    - 정보통신망법 업데이트 자동 감지
    - predata 폴더 자동 갱신 시스템
    - 변경사항 감지 및 알림

[ ] ⚠️ 임베딩 시스템 최적화 (BaseProcessor 개선)
    - **현재**: 개별 임베딩 처리 → **개선**: 배치 처리
    - **현재**: 800자 고정 청킹 → **개선**: 의미 단위 청킹
    - **현재**: 캐싱 없음 → **개선**: Redis 캐싱 시스템
    - **현재**: top_k=3 고정 → **개선**: 동적 임계값

🔧 1.2 RAGAS 평가 시스템 구축 - **신규 핵심 시스템**
------------------------------------------------
[ ] 🚨 RAGAS Dataset 구축 (evaluation/ragas_dataset.py)
    - **CSV 형식**: question, contexts, ground_truth, answer
    - **데이터 소스**: 화이트리스트, 심사 통과 템플릿 활용
    - **샘플 크기**: 초기 200개 → 점진적 확장 1000개
    - **품질 관리**: 수동 검증 + 자동 품질 체크

[ ] 🚨 커스텀 RAGAS 평가 기준 설정 (evaluation/custom_criteria.py)
    - **Faithfulness** (임계값: 0.85): 가이드라인 준수도
      * "카카오 알림톡 정책 준수하는가?"
      * "정보통신망법 조항 위반하지 않는가?"
      * "필수 항목(발신자, 수신거부) 포함되어 있는가?"
    
    - **Answer Relevancy** (임계값: 0.90): 사용자 요청 부합도
      * "사용자 요청 목적에 부합하는가?"
      * "추출된 엔티티가 적절히 반영되었는가?"
    
    - **Context Recall** (임계값: 0.80): 가이드라인 활용도
      * "화이트리스트 패턴을 적절히 활용했는가?"
      * "블랙리스트 위험 요소를 피했는가?"
    
    - **Context Precision** (임계값: 0.85): 검색 정확도
      * "검색된 가이드라인이 도움이 되는가?"
      * "불필요한 정보가 포함되지 않았는가?"

[ ] 🚨 RAGAS Evaluator 구현 (evaluation/ragas_evaluator.py)
    - 3회 반복 평가 시스템 (일관성 검증)
    - 평가 결과 통계 분석 (평균/표준편차)
    - 실패 원인 자동 분석 및 피드백
    - 개선 제안 자동 생성

🔧 1.3 통합 워크플로우 (RAG 단계)
------------------------------
[ ] ⚠️ main.py 개선 (기존 TemplateSystem 고도화)
    ```python
    class EnhancedTemplateSystem:
        1. LLM-as-a-judge → 입력 검증
        2. SemScore Modifier → 부적절 내용 수정
        3. Enhanced RAG → 템플릿 생성  
        4. RAGAS Evaluation → 품질 검증 (3회)
        5. 결과 반환 or 재생성
    ```

**🎯 Phase 1 목표**:
- 현재 시스템 안정화 + 고도화
- RAGAS 평가 기준 확립 
- LLM-as-a-judge + SemScore 통합
- 실시간 데이터 업데이트
- **예상 정확도**: 85-90% → 90-93%
- **소요 시간**: 2주
- **월 운영비용**: $8-12

🚨 **PHASE 2: LangChain Agent 시스템 (3-4주) - AI.png Agent 구조 구현**
=====================================================================

🔧 2.1 Agent1 구현 (가이드라인 검증 Agent) - **AI.png 핵심**
-------------------------------------------------------
[ ] 🚨 Agent1 클래스 생성 (agents/agent1.py) - **AI.png 다이아몬드 분기**
    ```python
    class GuidelineValidationAgent:
        def validate(self, user_input: str) -> Dict:
            # AI.png 플로우: YES/NO 분기 구현
            1. LLM-as-a-judge 1차 검증 
            2. 가이드라인 매칭 점수 계산 (0-100점)
            3. 컴플라이언스 위험도 평가
            4. Decision: PASS (≥80점) or FEEDBACK (<80점)
            
        def generate_feedback(self, issues: List) -> str:
            # 피드백 루프 구현 (AI.png NO 경로)
            1. SemScore 기반 구체적 개선 제안
            2. 화이트리스트 패턴 추천
            3. 법적 위험 요소 경고
    ```

[ ] 🚨 피드백 루프 시스템 (agents/feedback_loop.py)
    - **AI.png 순환 구조**: Agent1 FAIL → 피드백 → 사용자 재입력 → Agent1
    - **최대 재시도**: 3회 제한
    - **학습 기반 개선**: 실패 패턴 누적 학습
    - **사용자 가이드**: 구체적 수정 방향 제시

🔧 2.2 Agent2 + 4개 Tools 병렬 시스템 (핵심 구현) - **AI.png 병렬 구조**
-----------------------------------------------------------------
[ ] 🚨 tools/ 폴더 및 4개 Tool 클래스 생성 - **완전 신규**
    
    **BlackListTool** (tools/blacklist_tool.py):
    ```python
    class BlackListTool(BaseTool):
        name = "blacklist_validator"
        description = "블랙리스트 기반 위험 요소 검증"
        
        def _run(self, template: str) -> Dict:
            # predata/cleaned_black_list.md 활용
            1. 금지어/패턴 매칭 (정확 일치 + 유사도)
            2. SemScore 유사성 검사 (임계값: 0.7)
            3. 위험도 점수 계산 (0-100)
            4. 대체어 제안 (SemScore 기반)
            return {"risk_score": 점수, "issues": [], "suggestions": []}
    ```
    
    **WhiteListTool** (tools/whitelist_tool.py):
    ```python  
    class WhiteListTool(BaseTool):
        name = "whitelist_validator"
        description = "승인 패턴 기반 컴플라이언스 검증"
        
        def _run(self, template: str) -> Dict:
            # predata/cleaned_white_list.md 활용
            1. 승인된 템플릿 패턴 매칭
            2. 형식/구조 적합성 검증  
            3. 컴플라이언스 점수 계산
            4. 베스트 프랙티스 점수
            return {"compliance_score": 점수, "matches": [], "recommendations": []}
    ```
    
    **GuidelineTool** (tools/guideline_tool.py):
    ```python
    class GuidelineTool(BaseTool): 
        name = "guideline_checker"
        description = "통합 가이드라인 준수도 검증"
        
        def _run(self, template: str) -> Dict:
            # 모든 predata/*.md 파일 통합 검색
            1. 관련 가이드라인 벡터 검색 (top_k=5)
            2. 준수도 점수 계산 (RAGAS Context Recall 기반)
            3. 누락된 필수 요소 체크
            4. 권장사항 제시
            return {"guideline_score": 점수, "violations": [], "suggestions": []}
    ```
    
    **InfoCommLawTool** (tools/info_comm_law_tool.py):
    ```python
    class InfoCommLawTool(BaseTool):
        name = "legal_compliance_checker" 
        description = "정보통신망법 조항별 법적 검증"
        
        def _run(self, template: str) -> Dict:
            # predata/pdf_extraction_results.txt 활용
            1. 법령 조항별 체크리스트 검증
            2. 법적 위험도 평가 (고/중/저)
            3. 필수 법적 요소 확인 (수신거부, 발신자 정보 등)
            4. 위반 시 제재 사항 경고
            return {"legal_risk": "low/medium/high", "violations": [], "requirements": []}
    ```

[ ] 🚨 Agent2 + RunnableParallel 구현 (agents/agent2.py)
    ```python
    from langchain.tools import Tool
    from langchain.schema.runnable import RunnableParallel
    
    class MultimodalValidationAgent:
        def __init__(self):
            self.tools = {
                "blacklist": BlackListTool(),
                "whitelist": WhiteListTool(), 
                "guideline": GuidelineTool(),
                "legal": InfoCommLawTool()
            }
            
            # AI.png 병렬 처리 구현
            self.parallel_runner = RunnableParallel(**self.tools)
            
        def validate_parallel(self, template: str) -> Dict:
            # 4개 Tool 동시 실행 (AI.png Agent2 구조)
            results = self.parallel_runner.invoke(template)
            
            # 결과 집계 및 종합 판정
            final_decision = self.aggregate_results(results)
            
            # ALL PASS 필요 (AI.png 요구사항)
            return {
                "overall_pass": all(r["pass"] for r in results.values()),
                "individual_scores": results,
                "final_decision": final_decision,
                "improvement_suggestions": self.generate_improvements(results)
            }
    ```

🔧 2.3 SOT (Single Source of Truth) 시스템 - **AI.png SOT 노드**
------------------------------------------------------------
[ ] 🚨 SOTManager 구현 (core/sot_manager.py)
    - **중앙집중식 데이터 관리**: predata 폴더 전체 관리
    - **메타데이터 시스템**: 파일별 버전, 해시, 최종 수정일
    - **자동 갱신**: URL 스크래핑 결과 → SOT 업데이트
    - **일관성 보장**: Agent들의 동일한 데이터 소스 접근
    - **캐싱 시스템**: Redis 기반 고성능 캐싱

[ ] 🚨 SOT 조회 및 승인 시스템 (AI.png 플로우)
    ```python
    class SOTValidation:
        def check_template_approval(self, template: str, metadata: Dict) -> Dict:
            # AI.png SOT 검증 단계
            1. Agent1 PASS → Agent2 ALL PASS 확인
            2. RAGAS 3회 평가 ALL PASS (임계값 충족)
            3. SOT 기반 최종 승인 여부 결정
            4. 승인 시 템플릿 저장 + 메타데이터 기록
            
            return {"approved": True/False, "reason": "상세 사유"}
    ```

🔧 2.4 LangChain Agent Workflow 통합
----------------------------------
[ ] 🚨 MasterAgent 구현 (agents/master_agent.py)
    ```python
    class MasterAgent:
        def process_request(self, user_input: str) -> Dict:
            # AI.png 전체 플로우 구현
            
            # 1. LLM-as-a-judge + SemScore (Phase 1)
            judge_result = self.llm_judge.validate(user_input)
            if not judge_result["appropriate"]:
                return {"status": "rejected", "feedback": judge_result}
                
            # 2. Agent1 - 가이드라인 검증 (AI.png)
            agent1_result = self.agent1.validate(user_input)
            if agent1_result["score"] < 80:
                return {"status": "feedback", "suggestions": agent1_result["feedback"]}
                
            # 3. 템플릿 생성 (Enhanced RAG)
            template = self.template_generator.generate(user_input, agent1_result["context"])
            
            # 4. Agent2 - 병렬 검증 (AI.png)
            agent2_result = self.agent2.validate_parallel(template)
            if not agent2_result["overall_pass"]:
                return {"status": "failed", "issues": agent2_result["individual_scores"]}
                
            # 5. RAGAS 3회 평가
            ragas_scores = self.ragas_evaluator.evaluate_multiple(template, context, 3)
            if not ragas_scores["all_pass"]:
                return {"status": "quality_failed", "scores": ragas_scores}
                
            # 6. SOT 승인 확인 (AI.png)
            sot_result = self.sot_manager.check_approval(template, metadata)
            if sot_result["approved"]:
                return {"status": "approved", "template": template, "metadata": metadata}
            else:
                return {"status": "sot_rejected", "reason": sot_result["reason"]}
    ```

**🎯 Phase 2 목표**:
- AI.png 플로우차트 완전 구현
- Agent1 + Agent2 + SOT 시스템 구축  
- 4개 Tools 병렬 처리 (RunnableParallel)
- LangChain Agent 아키텍처 완성
- **예상 정확도**: 90-93% → 94-96%
- **소요 시간**: 3-4주
- **월 운영비용**: $12-18

🚨 **PHASE 3: LangGraph 고급 워크플로우 (5-6주) - 12.png 마이크로서비스 구조**
========================================================================

🔧 3.1 복잡한 조건부 플로우 구현 (LangGraph 고급 기능)
---------------------------------------------------
[ ] 🚨 LangGraph StateGraph 구현 (workflows/langgraph_workflow.py)
    ```python
    from langgraph.graph import StateGraph, END
    from typing import TypedDict
    
    class AlimtalkState(TypedDict):
        user_input: str
        judge_result: Dict
        agent1_result: Dict
        template: str
        agent2_result: Dict
        ragas_scores: Dict
        sot_decision: Dict
        final_result: Dict
        retry_count: int
        
    # AI.png 완전 구현
    workflow = StateGraph(AlimtalkState)
    
    # 노드 추가 (AI.png 각 단계)
    workflow.add_node("llm_judge", llm_judge_node)
    workflow.add_node("agent1_validate", agent1_validation_node)
    workflow.add_node("generate_template", template_generation_node)
    workflow.add_node("agent2_parallel", agent2_parallel_validation_node)
    workflow.add_node("ragas_evaluate", ragas_evaluation_node)
    workflow.add_node("sot_approval", sot_approval_node)
    workflow.add_node("feedback_generate", feedback_generation_node)
    
    # 조건부 엣지 (AI.png 다이아몬드 분기점들)
    workflow.add_conditional_edges(
        "llm_judge",
        lambda x: "agent1_validate" if x["judge_result"]["appropriate"] 
                 else "feedback_generate"
    )
    
    workflow.add_conditional_edges(
        "agent1_validate", 
        lambda x: "generate_template" if x["agent1_result"]["score"] >= 80
                 else "feedback_generate"
    )
    
    workflow.add_conditional_edges(
        "agent2_parallel",
        lambda x: "ragas_evaluate" if x["agent2_result"]["overall_pass"]
                 else "feedback_generate"
    )
    
    # 재시도 로직 (최대 3회)
    workflow.add_conditional_edges(
        "feedback_generate",
        lambda x: "llm_judge" if x["retry_count"] < 3 else END
    )
    ```

[ ] 🚨 상태 관리 및 메모리 시스템 (workflows/state_manager.py)
    - **대화 상태 유지**: 사용자별 세션 관리
    - **재시도 히스토리**: 실패 원인 및 개선 과정 추적
    - **학습 데이터 수집**: 성공/실패 패턴 자동 저장
    - **A/B 테스트 지원**: 다른 경로 성능 비교

[ ] 🚨 동적 플로우 라우팅 (workflows/dynamic_router.py)
    - **사용자 의도별 경로**: 긴급/일반/마케팅 분류
    - **복잡도별 경로**: 단순 템플릿 vs 복잡한 법적 검토  
    - **성능 최적화 경로**: 캐시된 결과 활용
    - **에러 복구 경로**: 부분 실패 시 복구 전략

🔧 3.2 마이크로서비스 아키텍처 구현 (12.png 반영)
-----------------------------------------------
[ ] 🚨 FastAPI AI 엔진 서버 분리 (backend/ai-engine/)
    ```python
    # FastAPI 서비스 구조
    from fastapi import FastAPI, BackgroundTasks
    from langgraph.graph import CompiledGraph
    
    app = FastAPI(title="AlimTalk AI Engine")
    
    # 비동기 LangGraph 실행
    @app.post("/api/v1/templates/generate")
    async def generate_template(request: TemplateRequest):
        # LangGraph 워크플로우 비동기 실행
        result = await langgraph_workflow.ainvoke({
            "user_input": request.content,
            "retry_count": 0
        })
        return result
        
    @app.post("/api/v1/templates/evaluate") 
    async def evaluate_template(request: EvaluationRequest):
        # RAGAS 3회 평가 비동기 실행
        scores = await ragas_evaluator.evaluate_async(
            request.template, request.context, runs=3
        )
        return scores
    ```

[ ] 🚨 Spring Boot API Gateway (backend/spring-api/)
    ```java
    @RestController
    @RequestMapping("/api/templates")
    public class TemplateController {
        
        @Autowired
        private AIEngineClient aiEngineClient;
        
        @Autowired 
        private MockKakaoClient mockKakaoClient;
        
        @PostMapping("/generate")
        public ResponseEntity<TemplateResponse> generateTemplate(
            @RequestBody TemplateRequest request) {
            
            // 1. AI Engine 호출 (FastAPI)
            AIEngineResponse aiResult = aiEngineClient.generateTemplate(request);
            
            // 2. Mock 카카오 API 심사 요청
            if (aiResult.isApproved()) {
                mockKakaoClient.submitForReview(aiResult.getTemplate());
            }
            
            return ResponseEntity.ok(TemplateResponse.from(aiResult));
        }
        
        @GetMapping("/{id}/status")
        public ResponseEntity<StatusResponse> getStatus(@PathVariable String id) {
            // 심사 상태 조회
            return ResponseEntity.ok(statusService.getStatus(id));
        }
    }
    ```

[ ] 🚨 Mock 카카오 API 시뮬레이터 (backend/mock-kakao-api/)
    ```python
    from fastapi import FastAPI
    import asyncio
    import random
    
    app = FastAPI(title="Mock Kakao API")
    
    @app.post("/api/v1/alimtalk/templates/review")
    async def submit_template_review(template: TemplateSubmission):
        # 실제 카카오 심사 프로세스 시뮬레이션
        
        # 1. 즉시 접수 응답
        submission_id = generate_submission_id()
        
        # 2. 백그라운드 심사 프로세스
        asyncio.create_task(
            simulate_review_process(submission_id, template)
        )
        
        return {"submission_id": submission_id, "status": "submitted"}
    
    async def simulate_review_process(submission_id: str, template: TemplateSubmission):
        # 실제 심사 소요시간 시뮬레이션 (30분-4시간)
        await asyncio.sleep(random.randint(1800, 14400))
        
        # 심사 결과 결정 (승인/반려)
        decision = make_review_decision(template)
        
        # Webhook 콜백 전송
        await send_webhook_callback(submission_id, decision)
    ```

🔧 3.3 고급 AI 학습 시스템 (사용자 요구사항 반영)
-----------------------------------------------
[ ] 🚨 반려사유 분석 및 학습 AI (ai_learning/rejection_analyzer.py)
    ```python
    class RejectionReasonAnalyzer:
        def __init__(self):
            self.gemini_model = genai.GenerativeModel("gemini-2.0-flash-exp")
            self.pattern_db = RejectionPatternDB()
            
        def analyze_rejection(self, template: str, reason: str) -> Dict:
            """반려 사유 분석 및 패턴 학습"""
            
            # 1. 반려 사유 자동 분류
            categories = self.classify_rejection_reason(reason)
            
            # 2. 템플릿에서 문제 부분 식별
            problematic_parts = self.identify_issues(template, reason)
            
            # 3. 유사한 과거 사례 검색
            similar_cases = self.pattern_db.find_similar_rejections(
                template, categories
            )
            
            # 4. 개선 방안 자동 생성
            improvements = self.generate_improvements(
                template, problematic_parts, similar_cases
            )
            
            # 5. 학습 데이터 저장
            self.pattern_db.store_rejection_pattern({
                "template": template,
                "reason": reason,
                "categories": categories,
                "improvements": improvements,
                "timestamp": datetime.now()
            })
            
            return {
                "reason_categories": categories,
                "problematic_parts": problematic_parts,
                "suggested_improvements": improvements,
                "confidence_score": 0.85
            }
    ```

[ ] 🚨 승인 템플릿 패턴 학습 (ai_learning/approval_pattern_learner.py)
    ```python
    class ApprovalPatternLearner:
        def learn_success_patterns(self, approved_templates: List[Dict]):
            """승인된 템플릿들의 성공 패턴 학습"""
            
            # 1. 승인 템플릿 특징 추출
            success_features = self.extract_success_features(approved_templates)
            
            # 2. 공통 패턴 식별
            common_patterns = self.identify_common_patterns(success_features)
            
            # 3. 성공 확률 예측 모델 학습
            self.train_success_predictor(approved_templates, common_patterns)
            
            # 4. 템플릿 생성에 피드백
            self.update_generation_guidelines(common_patterns)
            
        def predict_approval_probability(self, template: str) -> float:
            """템플릿 승인 가능성 예측"""
            features = self.extract_features(template)
            return self.success_predictor.predict_proba(features)[0][1]
    ```

[ ] 🚨 실시간 피드백 루프 (ai_learning/feedback_loop.py)
    ```python
    class RealtimeFeedbackLoop:
        def __init__(self):
            self.rejection_analyzer = RejectionReasonAnalyzer()
            self.approval_learner = ApprovalPatternLearner()
            self.template_optimizer = TemplateOptimizer()
            
        async def process_feedback(self, result: Dict):
            """실제 심사 결과 피드백 처리"""
            
            if result["status"] == "rejected":
                # 반려 사유 분석 및 학습
                analysis = await self.rejection_analyzer.analyze_rejection(
                    result["template"], result["reason"]
                )
                
                # 시스템 개선 적용
                await self.apply_improvements(analysis)
                
            elif result["status"] == "approved":
                # 승인 패턴 학습
                await self.approval_learner.learn_from_approval(result)
                
            # 실시간 시스템 업데이트
            await self.update_system_parameters(result)
    ```

🔧 3.4 완전한 워크플로우 통합 (최종 시스템)
----------------------------------------
[ ] 🚨 MicroserviceOrchestrator 구현 (orchestration/orchestrator.py)
    ```python
    class MicroserviceOrchestrator:
        def __init__(self):
            self.spring_api = SpringAPIClient()
            self.ai_engine = AIEngineClient()
            self.mock_kakao = MockKakaoClient()
            self.langgraph_workflow = self.load_langgraph()
            
        async def process_complete_workflow(self, user_request: str) -> Dict:
            """완전한 워크플로우 실행"""
            
            # 1. Spring Boot API Gateway 진입점
            gateway_response = await self.spring_api.receive_request(user_request)
            
            # 2. FastAPI AI Engine으로 LangGraph 실행
            ai_result = await self.ai_engine.execute_langgraph(user_request)
            
            # 3. AI 승인 시 Mock 카카오 API 심사 의뢰
            if ai_result["status"] == "approved":
                kakao_response = await self.mock_kakao.submit_review(ai_result["template"])
                
                # 4. 실시간 심사 결과 대기 및 학습
                final_result = await self.wait_for_final_decision(kakao_response["submission_id"])
                
                # 5. 결과 기반 AI 학습
                await self.feedback_loop.process_feedback(final_result)
                
                return final_result
            
            return ai_result
    ```

**🎯 Phase 3 목표**:
- LangGraph 고급 워크플로우 구현
- 12.png 마이크로서비스 아키텍처 완성
- 실시간 AI 학습 시스템 (반료사유+승인패턴)
- 완전한 카카오 심사 프로세스 시뮬레이션
- **예상 정확도**: 94-96% → 97-99%
- **소요 시간**: 4-5주  
- **월 운영비용**: $18-25

========================================
📋 사용자 질문에 대한 상세 답변
========================================

✅ **1. RAGAS Dataset 구성 방법**
-------------------------------
**Q: 화이트리스트, 심사 통과된 테스트 등으로 RAGAS 데이터셋을 만들어도 되는가?**
**A: ✅ 완벽하게 가능하며 매우 효과적입니다!**

```csv
# ragas_alimtalk_dataset.csv (추천 구조)
question,contexts,ground_truth,answer
"카페 적립 포인트 안내 템플릿 만들어줘","['정보통신망법: 영리목적 정보전송은...', '카카오 가이드라인: 적립포인트 안내 시...', '화이트리스트: 승인된 적립포인트 템플릿...']","[적립포인트 안내]\n#{고객명}님, 안녕하세요...(심사 통과한 실제 템플릿)","[적립포인트 안내]\n#{고객명}님, 안녕하세요...(AI 생성 템플릿)"
```

**데이터 소스 활용 방안:**
- **화이트리스트** → contexts로 활용 (승인된 패턴 제공)
- **심사 통과 템플릿** → ground_truth로 활용 (정답 기준)
- **가이드라인 문서** → contexts 보강 (정책 기준)
- **법령 정보** → contexts 추가 (컴플라이언스 기준)

✅ **2. CSV 파일 형식 요구사항**
----------------------------
**Q: CSV 파일 형식이어야 하는가?**
**A: ✅ 맞습니다. RAGAS는 CSV 형식을 권장합니다.**

```python
# RAGAS 데이터셋 로드 예시
from datasets import Dataset
import pandas as pd

# CSV 파일 로드
df = pd.read_csv("ragas_alimtalk_dataset.csv")

# RAGAS Dataset 형태로 변환
dataset = Dataset.from_pandas(df)

# 필수 컬럼들
required_columns = ['question', 'contexts', 'ground_truth', 'answer']
```

**추가 컬럼 권장사항:**
- `category`: 템플릿 카테고리 (예약, 결제, 이벤트 등)
- `difficulty`: 복잡도 (1-5점)
- `compliance_risk`: 컴플라이언스 위험도
- `approval_status`: 실제 심사 결과

✅ **3. RAGAS 평가 기준 설정**
---------------------------
**Q: 평가 기준을 사용자가 정해야 하는가?**
**A: ✅ 네, 도메인에 맞는 커스터마이징이 필요합니다.**

**기본 RAGAS 메트릭은 일반적이므로 알림톡 특화 기준 필요:**

```python
# 알림톡 특화 RAGAS 기준 (custom_criteria.py)
ALIMTALK_RAGAS_CRITERIA = {
    "faithfulness": {
        "threshold": 0.85,
        "weight": 0.3,
        "custom_prompts": [
            "생성된 템플릿이 정보통신망법을 준수하는가?",
            "카카오 알림톡 정책에 위반되는 내용이 있는가?",
            "수신거부 방법이 명시되어 있는가?"
        ]
    },
    "answer_relevancy": {
        "threshold": 0.90,
        "weight": 0.25, 
        "custom_prompts": [
            "사용자 요청 목적에 부합하는 템플릿인가?",
            "추출된 엔티티가 적절히 활용되었는가?"
        ]
    },
    "context_recall": {
        "threshold": 0.80,
        "weight": 0.25,
        "custom_prompts": [
            "화이트리스트 패턴을 적절히 참조했는가?", 
            "블랙리스트 위험 요소를 피했는가?"
        ]
    },
    "context_precision": {
        "threshold": 0.85,
        "weight": 0.20,
        "custom_prompts": [
            "검색된 가이드라인이 도움이 되었는가?",
            "불필요한 정보가 포함되지 않았는가?"
        ]
    }
}

# 종합 점수 계산
def calculate_alimtalk_score(ragas_scores: Dict) -> float:
    weighted_score = sum(
        score * ALIMTALK_RAGAS_CRITERIA[metric]["weight"] 
        for metric, score in ragas_scores.items()
    )
    return weighted_score
```

✅ **4. LLM-as-a-judge 활용 방안**
-------------------------------
**Q: 비속어 및 부적절한 내용 판단에 사용 가능한가?**
**A: ✅ 완벽하게 가능하며 매우 효과적입니다!**

```python
# LLM-as-a-Judge 실제 구현 예시
class AlimtalkContentJudge:
    def __init__(self):
        self.gemini_judge = genai.GenerativeModel("gemini-2.0-flash-exp")
    
    def judge_content_appropriateness(self, user_input: str) -> Dict:
        """부적절한 내용 종합 판단"""
        
        judge_prompt = f"""
        다음 알림톡 템플릿 요청을 종합적으로 분석해주세요:
        
        입력: "{user_input}"
        
        판단 기준:
        1. 비속어/욕설 (한국어, 은어, 초성 포함)
        2. 성적/선정적 표현
        3. 폭력적/혐오적 내용
        4. 불법/사기 관련 내용
        5. 카카오 알림톡 정책 위반 요소
        6. 정보통신망법 위반 가능성
        
        JSON 응답:
        {{
            "is_appropriate": true/false,
            "risk_level": "low/medium/high",
            "violation_categories": ["위반 항목들"],
            "problematic_phrases": ["문제가 되는 구체적 표현들"],
            "suggestions": ["개선 방안들"],
            "confidence": 0.95
        }}
        """
        
        response = self.gemini_judge.generate_content(judge_prompt)
        return json.loads(response.text)
```

**적용 시점:**
1. **사용자 입력 즉시** → 부적절 내용 1차 필터링
2. **Agent1 진입 전** → 가이드라인 검증 전 사전 검증  
3. **템플릿 생성 후** → 최종 결과물 품질 확인

✅ **5. SemScore + 수정본 제시 시스템**
-----------------------------------
**Q: SemScore로 유사성 판단 후 수정본 제시가 가능한가?**
**A: ✅ 매우 효과적이며 혁신적인 접근법입니다!**

```python
# SemScore 기반 스마트 수정 시스템
class SmartContentModifier:
    def __init__(self):
        self.sem_model = SentenceTransformer('distiluse-base-multilingual-cased')
        self.blacklist_embeddings = self.load_blacklist_embeddings()
        self.whitelist_alternatives = self.load_whitelist_alternatives()
        
    def analyze_and_suggest(self, problematic_input: str) -> Dict:
        """SemScore 기반 분석 및 수정본 생성"""
        
        # 1. 문제 단어/구문 식별
        risky_parts = self.identify_risky_content(problematic_input)
        
        # 2. 각 문제 부분에 대한 SemScore 계산
        modifications = {}
        for risky_text in risky_parts:
            # 유사성 기반 안전한 대체어 검색
            safe_alternatives = self.find_safe_alternatives(risky_text)
            modifications[risky_text] = safe_alternatives
            
        # 3. 통합 수정본 생성
        modified_content = self.generate_safe_version(
            problematic_input, modifications
        )
        
        # 4. 추가 컴플라이언스 보완
        final_content = self.add_compliance_elements(modified_content)
        
        return {
            "original": problematic_input,
            "issues_found": risky_parts,
            "modifications": modifications,
            "suggested_content": final_content,
            "compliance_improvement": self.calculate_improvement_score(
                problematic_input, final_content
            ),
            "explanation": "수정 이유 및 개선 사항 설명"
        }
        
    def find_safe_alternatives(self, risky_text: str, threshold: float = 0.7) -> List[str]:
        """SemScore 활용 안전한 대체어 검색"""
        
        risky_embedding = self.sem_model.encode([risky_text])
        
        # 화이트리스트에서 유사한 안전한 표현 검색
        similarities = cosine_similarity(
            risky_embedding, 
            self.whitelist_embeddings
        )[0]
        
        # 임계값 이상의 유사한 안전 표현들 반환
        safe_indices = np.where(similarities >= threshold)[0]
        safe_alternatives = [
            self.whitelist_terms[idx] for idx in safe_indices
        ]
        
        return sorted(safe_alternatives, key=lambda x: similarities[safe_indices])[:3]
```

**실제 활용 예시:**
- **문제 입력**: "술집 이벤트 홍보 템플릿"
- **SemScore 분석**: '술집' → 유흥업소 관련 위험 감지
- **대체어 제안**: '레스토랑', '음식점', '다이닝'
- **수정본**: "레스토랑 이벤트 홍보 템플릿"
- **컴플라이언스 보완**: 법적 요구사항 추가

========================================
🎯 최종 개발 로드맵 요약 (AI.png + 12.png 완전 구현)
========================================

**📅 전체 타임라인: 10-12주**

**Phase 1 (1-2주)**: RAG 강화
- LLM-as-a-judge + SemScore 시스템 
- RAGAS 평가 시스템 구축
- 현재 시스템 최적화

**Phase 2 (3-4주)**: LangChain Agent
- AI.png Agent1 + Agent2 구현
- 4개 Tools 병렬 처리
- SOT 시스템 구축

**Phase 3 (5-6주)**: LangGraph + 마이크로서비스
- 12.png 아키텍처 구현
- 실시간 AI 학습 시스템
- 완전한 워크플로우 통합

**🎯 최종 시스템 특징:**
✅ AI.png 플로우차트 100% 구현
✅ 12.png 마이크로서비스 아키텍처 완성
✅ RAGAS 기반 품질 평가 시스템
✅ LLM-as-a-judge 콘텐츠 검증
✅ SemScore 기반 스마트 수정 시스템
✅ 실시간 반려사유 + 승인패턴 학습
✅ 완전 자동화된 카카오 심사 프로세스

**💰 비용 분석:**
- 개발 비용: 전체 $8,000-12,000
- 월 운영비: $25-35 (100명 사용 기준)
- ROI: 6개월 내 손익분기점 달성 예상

**📈 성능 목표:**
- 최종 정확도: 97-99%
- 응답 시간: 3-5초
- 가용성: 99.5% 이상

🔥 **HIGH - 기존 시스템 강화 (2-3주)**  
5. **SOT 시스템**: predata 중앙 관리
   - 현재: 하드코딩된 파일 리스트 → 동적 관리
   
6. **임베딩/검색 최적화**: 
   - 현재: 개별 처리 → 배치 처리
   - 현재: 고정 top_k → 동적 임계값
   
7. **AI 학습 시스템**: 승인/반려 패턴 학습
   - 사용자 요구사항 (반려사유+템플릿 학습)

8. **Spring Boot + FastAPI 분리** (12.png 반영)
   - 현재: 단일 Python 시스템 → 마이크로서비스

⚡ **HIGH (2-3주)**  
- **Mock 카카오 API 시뮬레이터 구축**
- **마이크로서비스 간 통신 최적화**
- RAGAS 3회 평가 및 기준 시스템
- 완전한 파이프라인 통합 (Spring Boot ↔ FastAPI ↔ MySQL)
- 기본 실데이터 테스트

💡 **MEDIUM (4주 이후)**
- 고도화된 검증 시스템
- 성능 최적화
- 운영 모니터링

========================================
🎉 최종 검증 체크리스트
========================================

✅ **시스템 완성도 검증**
[ ] 심사 통과 템플릿 100개로 95% 이상 정확도
[ ] 심사 반려 템플릿 100개로 90% 이상 탐지율
[ ] 평균 응답시간 30초 이내
[ ] 메모리 사용량 2GB 이내

✅ **품질 보증 검증**  
[ ] RAGAS 점수 일관성 (3회 측정 표준편차 5점 이내)
[ ] Agent2 Tools 병렬처리 정상 동작
[ ] MySQL 데이터 무결성 100%
[ ] 에러 복구 시스템 정상 동작

✅ **운영 준비 검증**
[ ] 24시간 연속 운영 테스트
[ ] 동시 사용자 100명 부하 테스트  
[ ] 장애 복구 시나리오 테스트
[ ] 보안 취약점 점검 완료

========================================
🎉 현재 코드 분석 완료 - 핵심 개선사항 요약
========================================

**📊 현재 상태 평가**
✅ **잘 구현된 부분**:
- Gemini API 연동 (BaseProcessor)
- 기본적인 엔티티 추출 (EntityExtractor) 
- 템플릿 생성 로직 (TemplateGenerator)
- predata 파일들 로드 및 임베딩

❌ **완전히 누락된 부분** (AI.png 대비):
- Agent1 (가이드라인 검증)
- Agent2 (병렬 검증)  
- 4개 Tools (BlackList, WhiteList, Guideline, InfoCommLaw)
- RunnableParallel 구조
- SOT 시스템
- 승인/반려 결정 로직

⚠️ **개선 필요한 부분**:
- predata 활용 방식 (단순 참조 → 검증 로직)
- 임베딩 처리 (개별 → 배치)
- 검색 정확도 (고정 → 동적)

**🚀 다음 단계 액션 플랜**:
1. Agent1 구현으로 AI.png 플로우 시작점 구축
2. 4개 Tools로 실제 검증 로직 추가
3. Agent2로 병렬 처리 아키텍처 완성
4. AI 학습 시스템으로 지속적 개선 체계 구축

이 분석을 바탕으로 AI.png 플로우차트를 완벽히 구현하여
사용자의 비전인 "반려사유+반려템플릿, 승인템플릿 학습 AI" 시스템을 
완성해나가세요! 🚀💪

**📝 작성 완료**: 2025-08-28 - 현재 코드 대비 완전한 개발 가이드